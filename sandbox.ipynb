{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "seq_len = 21\n",
    "vocab_size = 1000\n",
    "embd_size = 200\n",
    "kernel = (5, embd_size)\n",
    "out_chs = 64\n",
    "bs = 11\n",
    "ans_size = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xa torch.Size([11, 1, 21, 200])\n",
      "A <built-in method size of torch.FloatTensor object at 0x7fb1869fdbc8> B torch.Size([11, 64, 21, 1])\n",
      "h0 torch.Size([11, 64, 21, 1])\n",
      "out torch.Size([11, 100])\n"
     ]
    }
   ],
   "source": [
    "# In : (N, sentence_len)\n",
    "# Out: (N, sentence_len, embd_size)\n",
    "class GatedCNN(nn.Module):\n",
    "    def __init__(self, seq_len, vocab_size, embd_size, kernel, out_chs, ans_size):\n",
    "        super(GatedCNN, self).__init__()\n",
    "        self.embd_size = embd_size\n",
    "        self.embedding = nn.Embedding(vocab_size, embd_size)\n",
    "        # nn.Conv1d(in_channels, out_channels, kernel_size, stride=1, padding=0, ...\n",
    "        self.conv      = nn.Conv2d(1, out_chs, kernel, padding=(2, 0)) # )2, 99\n",
    "        self.conv_gate = nn.Conv2d(1, out_chs, kernel, padding=(2, 0)) # )2, 99\n",
    "        # todo bias\n",
    "        \n",
    "        self.conv2      = nn.Conv2d(out_chs, out_chs, (kernel[0], 1), padding=(2, 0)) # )2, 99\n",
    "        self.conv_gate2 = nn.Conv2d(out_chs, out_chs, (kernel[0], 1), padding=(2, 0)) # )2, 99\n",
    "        \n",
    "        self.fc = nn.Linear(out_chs*seq_len, ans_size)\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x: (N, seq_len)\n",
    "        # Embedding\n",
    "        bs = x.size(0) # batch size\n",
    "        seq_len = x.size(1) # number of words in a sentence\n",
    "        x = self.embedding(x) # (bs, word_len, embd_size)\n",
    "\n",
    "        # CNN\n",
    "        x = x.unsqueeze(1) # (bs, Cin, seq_len, embd_size), insert Channnel-In dim\n",
    "        # Conv2d\n",
    "        #    Input : (bs, Cin, Hin, Win )\n",
    "        #    Output: (bs, Cout,Hout,Wout) \n",
    "        print('xa', x.size())\n",
    "        A = self.conv(x) # (bs, Cout, seq_len, 1?)\n",
    "        B = self.conv_gate(x) # (bs, Cout, seq_len, 1?)\n",
    "        print('A', A.size, 'B', B.size())\n",
    "        h0 = A * F.sigmoid(B) # (bs, Cout, seq_len, 1?)\n",
    "        print('h0', h0.size())\n",
    "        \n",
    "        A2 = self.conv2(h0)\n",
    "        B2 = self.conv_gate2(h0)\n",
    "        h1 = A2 * F.sigmoid(B2) # (bs, Cout, seq_len, 1?)\n",
    "        \n",
    "        # todo residual\n",
    "        \n",
    "        hL = h1 # (bs, Cout, seq_len, 1?)\n",
    "        hL = hL.view(bs, -1) # (bs, Cout*seq_len)\n",
    "        out = self.fc(hL) # (bs, ans_size)\n",
    "        print('out', out.size())\n",
    "        return out\n",
    "\n",
    "model = GatedCNN(seq_len, vocab_size, embd_size, kernel, out_chs, ans_size)\n",
    "x = Variable(torch.zeros((bs, seq_len)).type(torch.LongTensor))\n",
    "y = model(x)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
